{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from algocryptos_preprocessing.ipynb\n",
      "importing Jupyter notebook from algocryptos_gridsearch.ipynb\n"
     ]
    }
   ],
   "source": [
    "from utils_csa import show_model_accuracy, save_obj, load_obj\n",
    "\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "\n",
    "# Lib to calcul financial indicators https://github.com/mrjbq7/ta-lib\n",
    "import talib\n",
    "\n",
    "# Lib to import ipynb : https://pypi.org/project/import-ipynb/\n",
    "import import_ipynb\n",
    "import algocryptos_preprocessing as alg_preproc\n",
    "import algocryptos_gridsearch as alg_gridsearch\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "#np.set_printoptions(threshold='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ PARAMETERS ------------------ #\n",
    "# ['y_+3h_value', 'y_+3h_classif',, 'y_+6h_value', 'y_+6h_classif', 'y_+12h_value', 'y_+12h_classif','y_+1d_value', 'y_+1d_classif', 'y_+2d_value', 'y_+2d_classif', 'y_+3d_value', 'y_+3d_classif', 'y_+7d_value', 'y_+7d_classif', 'y_+15d_value', 'y_+15d_classif', 'y_+30d_value', 'y_+30d_classif']\n",
    "id_cryptocompare = \"7605\" # ether 7605\n",
    "y_to_be_considered = 'y_+1d_classif'\n",
    "close_price_increase_targeted = +5\n",
    "threshold = 0.75\n",
    "dict_hours_labels  = {3:'3h', 6:'6h', 12:'12h', 24:'1d', 24*2:'2d', 24*3:'3d', 24*7:'7d', 24*15:'15d', 24*30:'30d'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------ LOAD DATA FROM DATABASE ------------------ #\n",
    "\n",
    "# ONE CRYPTO\n",
    "#df = alg_preproc.get_global_dataset_for_crypto(\"236131\")\n",
    "#df2 = df.reset_index(drop=True)\n",
    "\n",
    "# TOP N CRYPTOS\n",
    "#dict_df = alg_preproc.get_global_datasets_for_top_n_cryptos(10)\n",
    "\n",
    "# ------------------ LOAD DATA FROM FILE ------------------ #\n",
    "#save_obj(dict_df, 'dict_df_2018_10_31')\n",
    "dict_df = load_obj('dict_df_2018_10_26')\n",
    "#dict_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ PRE-PROCESSING : Calcul y + split data ------------------ #\n",
    "columns_nb = 0\n",
    "df_new_dict = {}\n",
    "df_new_list = []\n",
    "\n",
    "def calcul_values_of_y(df, dict_hours_labels, increase_target_pct):\n",
    "    increase_target_pct = increase_target_pct / 100\n",
    "    \n",
    "    for key in dict_hours_labels:\n",
    "        label_value = 'y_+' + dict_hours_labels[key] + '_value'\n",
    "        label_classif = 'y_+' + dict_hours_labels[key] + '_classif'\n",
    "        # calcul several y searched (value)\n",
    "        df[label_value] = df.close_price.shift(-key)\n",
    "        \n",
    "        # perform calcul to use binary classification\n",
    "        df[label_classif] = ((df[label_value] - df['close_price']) / df['close_price']) > increase_target_pct\n",
    "    \n",
    "    return df\n",
    "\n",
    "def do_split_data(df_p, columns_nb_p):\n",
    "    # separe x,y\n",
    "    X = df_p.iloc[:,range(1, columns_nb_p)]\n",
    "    y = df_p.iloc[:,range(columns_nb_p, len(df_p.columns))]\n",
    "\n",
    "    # split data in training / validating / testing\n",
    "    return train_test_split(X, y, random_state=0, shuffle=False)\n",
    "\n",
    "# calcul y for each crypto\n",
    "for key_id_cryptocompare, df_one_crypto in dict_df.items():\n",
    "    # number of columns before adding y values - could be done once only\n",
    "    columns_nb = len(df_one_crypto.columns)\n",
    "\n",
    "    # calcul all y values we are interested in and add it to the dataframe\n",
    "    df_one_crypto = calcul_values_of_y(df_one_crypto.copy(), dict_hours_labels, close_price_increase_targeted)\n",
    "\n",
    "    # remove rows where y can't be calculed (need more data in the future)\n",
    "    df_one_crypto.dropna(subset=list(df_one_crypto.iloc[:,range(columns_nb, len(df_one_crypto.columns))]), inplace=True)\n",
    "    \n",
    "    df_new_dict[key_id_cryptocompare] = df_one_crypto\n",
    "    df_new_list.append(df_one_crypto)\n",
    "\n",
    "# concat to get only one dataframe instead of a list of dataframes\n",
    "df_global = pd.concat(df_new_list).sort_index()\n",
    "df_global.reset_index(drop=True)\n",
    "\n",
    "# All cryptos\n",
    "X_train, X_test, y_train, y_test = do_split_data(df_global, columns_nb)\n",
    "\n",
    "# The one to predict\n",
    "X_train_one_crypto, X_test_one_crypto, y_train_one_crypto, y_test_one_crypto = do_split_data(df_new_dict[id_cryptocompare], columns_nb)\n",
    "X_test = X_test_one_crypto\n",
    "y_test = y_test_one_crypto\n",
    "\n",
    "# TODO : To be used to avoid overitting : No tuning while using testing data, only validation\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# ------------------ PRE-PROCESSING : Scaling Data ------------------ #\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#X_train_scaled = X_train\n",
    "#X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# ALGO : RANDOM FOREST WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "rf_best_estimator, rf_best_params = alg_gridsearch.start_randomizedSearchCV_random_forest(X_train_scaled, \n",
    "                                                                                          y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', rf_best_estimator, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_precision_recall_curve=True, do_features_importance=True, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', rf_best_estimator, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : MLPC WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "mlpc_best_estimator, mlpc_best_params = alg_gridsearch.start_randomizedSearchCV_mlpc(X_train_scaled, \n",
    "                                                                                     y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', mlpc_best_estimator, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', mlpc_best_estimator, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : XGBoost WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "xgboost_best_estimator, xgboost_best_params = alg_gridsearch.start_randomizedSearchCV_xgboost(X_train_scaled, \n",
    "                                                                                           y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('GradientBoostingClassifier - Train', xgboost_best_estimator, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('GradientBoostingClassifier - Test', xgboost_best_estimator, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : RANDOM FOREST\n",
    "# -----------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#, n_estimators=100, max_features='auto', max_depth=5, criterion='entropy', class_weight=\"balanced\"\n",
    "clf = RandomForestClassifier(random_state=0, class_weight=\"balanced\", bootstrap=False,\n",
    " criterion='entropy',\n",
    " max_depth=11, #5\n",
    " max_features='auto',\n",
    " min_samples_leaf=4,\n",
    " min_samples_split=10,\n",
    " n_estimators=83).fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', clf, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_precision_recall_curve=True, do_features_importance=True, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', clf, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "\n",
    "# proba : to be shown by prediction, bien comprendre !\n",
    "probas = clf.predict_proba(X_test_scaled)[:,1]\n",
    "pprint(np.sort(probas))\n",
    "pprint(clf.get_params())\n",
    "\n",
    "# clf.decision_path(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : MLPClassifier - Neural Network (cf. Module+4 for tuning)\n",
    "# -----------------------\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [130, 130], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('MLPClassifier - Neural Network - Train', nnclf, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_roc_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('MLPClassifier - Neural Network - Test', nnclf, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_roc_curve=True, do_features_importance=False, threshold=threshold)\n",
    "\n",
    "# proba : to be shown by prediction, bien comprendre !\n",
    "#print(pd.DataFrame(nnclf.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : XGBOOST (cf. Module+4 for tuning)\n",
    "# -----------------------\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier().fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('XGBClassifier - Train', xgbc, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_roc_curve=True, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('XGBClassifier - Test', xgbc, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_roc_curve=True, do_precision_recall_curve=True, do_features_importance=True, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
