{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Global : \n",
    "    # 0 / Read : What is being done elsewhere, feature enginerring, algo, etc.\n",
    "    # 1 / Testing phase + take ownership of the code\n",
    "        # 1.1 / Test y_value and y_classif to be sure it's well calculated\n",
    "        # 1.2 / Understand well what the code is doing end-to-end\n",
    "    # 2 / Data vizualisation : Re-read MOOC + articles, what can I do ? Correlations, etc. => Visiblement aime bien les booleans !\n",
    "    # 3 / Choose features + add with features engineering if needed\n",
    "        # 3.1 / Other indicators - 10d-20d-30d, etc. ?\n",
    "        # 3.2 / Add info about trend 1h, 12h, 24h, 3d, 7d, 15d, 30d, etc. ?\n",
    "        # 3.3 / Volume indicators\n",
    "    # 4 / Create an automate that can :\n",
    "        # 4.1 / Test different y, different % increase / deacrease, different algo\n",
    "        # 4.2 / Try predicting the next hour / next 3h !!! It's stupid to predict +12h whereas I'll have more accurate data after that...\n",
    "        # 4.3 / Do Gridsearch or other kind of search to find good parameters\n",
    "        # 4.4 / Export results in a way that they are easy to choose    \n",
    "    # 5 / Try value instead of classif ?\n",
    "    # 6 / Try to learn with multiple dataset of different crypto ?\n",
    "    # 7 / Validation : Find ways to validate models, treshold, proba, etc.\n",
    "    # 8 / Do TA on bitcoin also when included in crypto dataset\n",
    "    \n",
    "    # Try to optimize each algo at a time, see if I can use other algo \n",
    "    \n",
    "# https://medium.com/auquan/https-medium-com-auquan-machine-learning-techniques-trading-b7120cee4f05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DATA VIZUALISATION ------------------ #\n",
    "\n",
    "# correlations (to be done with y to be searched, here not interesting...)\n",
    "#print(df.close_price.corr(df.reddit_subscribers))\n",
    "#print(df.close_price.corr(df.reddit_subscribers_slope))\n",
    "#print(df.close_price.corr(df.volume_aggregated))\n",
    "#print(df.close_price.corr(df.volume_aggregated_slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection / Reduce dimensionality\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA()\n",
    "# pca.fit(X_train_scaled)\n",
    "# cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "# plt.plot(cumsum)\n",
    "# plt.plot([0, len(X_train_scaled[0])], [0.97, 0.97],'r--')\n",
    "# plt.show()\n",
    "\n",
    "# # TODO : Reduce\n",
    "# pca = PCA(n_components=0.97)\n",
    "# X_reduced = pca.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tp = df2.iloc[:,0:123]\n",
    "#df_tp.reddit_subscribers_pct_change_1d.sort_values()\n",
    "#tmp = scaler.fit_transform(df_tp)\n",
    "#df2 = df2.replace([np.inf, -np.inf], np.nan).dropna(how=\"all\")\n",
    "\n",
    "#del dict_df[\"236131\"]\n",
    "\n",
    "#df_global.info(memory_usage='deep')\n",
    "\n",
    "# figure\n",
    "#fig1 = plt.figure(figsize=(15,15))\n",
    "#df.gg_trend_value_compared_pct_change_6m.plot(color='black')\n",
    "##df2.volume_aggregated.plot(secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "c = X_train.corr()\n",
    "#plt.figure(figsize=(10,10))\n",
    "#seaborn.heatmap(c, cmap='RdYlGn_r', mask = (np.abs(c) <= 0.8))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for correlations\n",
    "#for col in df3.columns.values:\n",
    "#    if df3[col].corr(df3['y_+1d_classif']) > 0.2:\n",
    "#        print(col + ' - ' + str(df3[col].corr(df3['y_+1d_classif'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : NAIVE BAYES - GAUSSIANNB\n",
    "# -----------------------\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('NAIVE BAYES - GaussianNB - Train', clf, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_roc_curve=True, do_features_importance=False)\n",
    "show_model_accuracy('NAIVE BAYES - GaussianNB - Test', clf, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_roc_curve=True, do_features_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ MODEL FITTING ------------------ #\n",
    "\n",
    "# -----------------------\n",
    "# ALGO : DUMMY CLASSIFIER\n",
    "# -----------------------\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy = 'most_frequent').fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('DummyClassifier - Train', dummy_clf, X_train_scaled, y_train[y_to_be_considered], X_train.columns)\n",
    "show_model_accuracy('DummyClassifier - Test', dummy_clf, X_test_scaled, y_test[y_to_be_considered], X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : SVC - (cf. Module+3 for tuning)\n",
    "# -----------------------\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1).fit(X_train_scaled, y_train[y_to_be_considered])\n",
    "\n",
    "\n",
    "show_model_accuracy('SVM - Train', svm, X_train_scaled, y_train[y_to_be_considered], X_train.columns, do_roc_curve=True, do_features_importance=False)\n",
    "show_model_accuracy('SVM - Test', svm, X_test_scaled, y_test[y_to_be_considered], X_test.columns, do_roc_curve=True, do_features_importance=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
