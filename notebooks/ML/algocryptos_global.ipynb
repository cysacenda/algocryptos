{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL : What am I searching for ?\n",
    "        # => To predict with the best possible accuracy (proba) an event (+/- xx% variation of close_price)\n",
    "        # What for ?\n",
    "            # => To be able to balance my portfolio (sell what should go down for what should go up)\n",
    "            # => Sell crypto for Stable coin / Or buy crypto with Stable Coin\n",
    "########\n",
    "\n",
    "# Advices : \n",
    "    # Be careful to scaling, min / max can change in the future..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE\n",
    "    # 1 / Industrialization : \n",
    "        # Dataset for TOP 20 cryptos + capacity to learn from top 20 and predict 1 : DONE !\n",
    "    # 2 / Gérer le fait qu'on a des datasets déséquilibrés ? : OK\n",
    "    # 3 / Gérer l'overfitting de ouf : OK\n",
    "    # 4 / Play with Treshold\n",
    "    # 4 bis / \n",
    "        # => ROC Curve, learning curve & precision / recall curve au top et bien comprendre !       \n",
    "            # => Lire tout : https://classeval.wordpress.com/introduction/introduction-to-the-roc-receiver-operating-characteristics-plot/\n",
    "        # => cf. schéma avec 2 lignes de Treshold. Le treshold ça marche comment ? Il est ou sur precision ou recall ? \n",
    "        # => Est-ce que ça a un sens ?? Bien comprendre !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Now :\n",
    "    \n",
    "    # 5 / Coder la systématisation :\n",
    "        # Valeurs par défaut pour algo, checker un peu ce qu'il faut pour éviter overfitting (dépend nb crytpos !)\n",
    "        # df_logging : ajout metrics + trucs sérialisé pour pouvoir afficher graph ?\n",
    "        \n",
    "    # 5 bis : Unbalanced : downsampling majority class or upsampling minority class ! cf. livre ML finance\n",
    "        # Est-ce nécessaire pour améliorer l'apprentissage ou juste pour analyser la perf de l'algo ?\n",
    "        # Sinon utiliser le param \"balanced\" => ex. Random forest\n",
    "        # https://elitedatascience.com/imbalanced-classes\n",
    "           \n",
    "    # 5 ter / Faire du gridsearch puis optimiser avec treshold\n",
    "        # Jouer un peu avec les algo et gridsearch pour bien comprendre (paramètres, fonctionnement, etc.)\n",
    "                # => Comment fonctionne l'amélioration via Precision score, etc. ? Tester + comprendre\n",
    "         # cf. schéma systematisation + prendre en compte Treshold\n",
    "                # => Evaluer selon différents Treshold : https://classeval.wordpress.com/introduction/model-wide-evaluation/\n",
    "        # Trouver un moyen pour que le ranking des modèles créés par GridSearch soit estimé en fonction de :\n",
    "        # precision + pas d'overfitting (scores train / test à peu près identiques)\n",
    "    \n",
    "    \n",
    "    # 5 quater / \n",
    "        # Switcher vers coinmarketcap api pro free tiers ? https://pro.coinmarketcap.com/pricing\n",
    "        # Sécuriser (si erreur api etc. => backup data des tables, etc.)\n",
    "                \n",
    "    \n",
    "    # 6 / Construire algo de strategy backtest Buy / Sell + indicateur de stratégie (prendre en compte prévisions d'augmentation et prévisions de baisse)  \n",
    "    \n",
    "    # 7 / Une fois que j'ai fait tout ça :\n",
    "        # lecture + recherche internet d'inspiration / travaux semblables (cf. livres)\n",
    "        # Feature engineering :\n",
    "            # New :\n",
    "                # Variance close price, volumes 3h, 6h, 12h, 24h, etc., more indicators on different scale\n",
    "                # Mean 24h price\n",
    "                # Mean 24h price - current price\n",
    "            # Delete useless ? Do real feature engineering with data vizualisation, correlation, etc.\n",
    "            # Impact feature engineering (correlation, suppression feature useless, etc.) cf. algocryptos_tests\n",
    "    \n",
    "    # 8 / Others :\n",
    "        # Serialize scikit learn model: http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "        # Use cross validation ?\n",
    "        # Différents algo de scaling en preprocessing\n",
    "        # Mieux comprendre ce qui est fait par l'algo, ex Randomforest, afficher arbre avec seuils, etc.\n",
    "        # Voir si certaines cryptos quand rajouter pour learning foutent la merde\n",
    "        \n",
    "    # 9 / A terme je pourrais avoir :\n",
    "        # Des modèles qui se mettent à jour automatiquement\n",
    "        # Pleins de modèles utilisés à différentes échelles pour savoir si il faut vendre ou acheter ! \n",
    "            # cf. que faire en fonction des différentes probas\n",
    "        # Show learning curve ? Precision / Recall curve Other metrics ? Jouer sur Treshold pour maximiser précision\n",
    "        # Deploy Model in AWS (serverless, cf. tuto https://medium.com/@patrickmichelberger/how-to-deploy-a-serverless-machine-learning-microservice-with-aws-lambda-aws-api-gateway-and-d5b8cbead846\n",
    "        # Use AWS for model fitting ?\n",
    "    # 10 / Faire tourner plusieurs modèles / crypto, \n",
    "        # 1 basé sur learning pur crypto, un sur top n.\n",
    "        # 1 sur hausse, baisse, \n",
    "        # 1 en fonction % augmentation / baisse\n",
    "        # achats / ventes dépendent des signaux des différents modèles\n",
    "        # Next step ? un super modèle qui utilise les probas des modèles précédents pour donner signaux achats / vente => ré enforcement learning ?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#Image(filename='Schema.jpg')\n",
    "#Image(filename='Systematisation.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from algocryptos_preprocessing.ipynb\n",
      "importing Jupyter notebook from algocryptos_gridsearch.ipynb\n"
     ]
    }
   ],
   "source": [
    "from utils_csa import show_model_accuracy, save_obj, load_obj, evaluate_model, evaluate_model_formated\n",
    "\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Lib to calcul financial indicators https://github.com/mrjbq7/ta-lib\n",
    "import talib\n",
    "\n",
    "# Lib to import ipynb : https://pypi.org/project/import-ipynb/\n",
    "import import_ipynb\n",
    "import algocryptos_preprocessing as alg_preproc\n",
    "import algocryptos_gridsearch as alg_gridsearch\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "#pd.set_option('display.max_rows', 150)\n",
    "#pd.set_option('display.max_columns', 150)\n",
    "\n",
    "#np.set_printoptions(threshold='nan')\n",
    "dict_hours_labels  = {3:'3h', 6:'6h', 12:'12h', 24:'1d', 24*2:'2d', 24*3:'3d', 24*7:'7d', 24*15:'15d', 24*30:'30d'}\n",
    "\n",
    "str_sql = 'postgresql://dbuser:algocryptos@localhost:9091/algocryptos'\n",
    "connection = create_engine(str_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ PARAMETERS for SYSTEMATIZATION ------------------ #\n",
    "\n",
    "# +3h  : (+/-) 2.5 / 5% / 7.5% / 10%\n",
    "# +6h  : (+/-) 2.5 / 5% / 7.5% / 10%\n",
    "# +12h : (+/-) 5% / 7.5% / 10%\n",
    "# +1d  : (+/-) 5% / 7.5% / 10%\n",
    "# +2d  : (+/-) 5% / 7.5% / 10 / 15%\n",
    "# +3d  : (+/-) 5% / 10% / 15% / 20%\n",
    "# +7d  : (+/-) 10% / 20% / 30%\n",
    "# +15d : (+/-) 10% / 20% / 30% / 50%\n",
    "# +30d : (+/-) 10% / 20% / 30% / 50% / 100%\n",
    "\n",
    "# dynamic params\n",
    "param_datasets_nb_cryptos = [5, 10, 20, 30, 100] # 100 = max\n",
    "params_y = {'3h':[2.5, 5, 7.5, 10],\n",
    "            '6h':[2.5, 5, 7.5, 10],\n",
    "            '12h':[2.5, 5, 7.5, 10],\n",
    "            '1d':[2.5, 5, 7.5, 10],\n",
    "            '2d':[10, 15, 20],\n",
    "            '3d':[10, 20, 30],\n",
    "            '7d':[10, 20, 30, 50],\n",
    "            '15d':[10, 20, 30, 50, 100],\n",
    "            '30d':[10, 20, 30, 50, 100, 200]}\n",
    "\n",
    "# cf. XLS\n",
    "param_crypto_learning = [1182, 7605, 5031, 202330, 4614, 166503, 3808, 321992, 5038, 310829, 127356, 3807, 204788, 27368, 5324, \n",
    "                   5285, 166390, 24854, 236131, 41192, 347235,187440, 186277, 16713, 4432, 112392, 808414, 19745, 107672, \n",
    "                   716725, 324068, 5039, 5280, 172091, 309621, 4430, 13072, 20333, 4433, 20131, 33022, 17778, 24294, 890645]\n",
    "\n",
    "param_crypto_predicting = [1182, 7605, 5031, 4614, 166503, 3808, 321992, 5038, 310829, 127356, 3807, 204788, 27368, 5324, \n",
    "                     5285, 166390, 236131, 41192, 187440, 186277, 112392, 808414, 19745, 107672, 716725, 324068, 172091, \n",
    "                     309621, 13072, 20333, 20131, 33022, 17778, 24294, 890645]\n",
    "\n",
    "tresholds = [0.5, 0.7, 0.8, 0.9]\n",
    "\n",
    "# ['y_+3h_value', 'y_+3h_classif',, 'y_+6h_value', 'y_+6h_classif', 'y_+12h_value', 'y_+12h_classif','y_+1d_value', 'y_+1d_classif', 'y_+2d_value', 'y_+2d_classif', 'y_+3d_value', 'y_+3d_classif', 'y_+7d_value', 'y_+7d_classif', 'y_+15d_value', 'y_+15d_classif', 'y_+30d_value', 'y_+30d_classif']\n",
    "predict_only_one_crypto = False\n",
    "\n",
    "do_scale = True\n",
    "do_pca = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crypto : 1182\n",
      "Crypto : 7605\n",
      "Crypto : 5031\n",
      "Crypto : 202330\n",
      "Crypto : 4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crypto : 1182\n",
      "Crypto : 7605\n",
      "Crypto : 5031\n",
      "Crypto : 202330\n",
      "Crypto : 4614\n",
      "Crypto : 166503\n",
      "Crypto : 3808\n",
      "Crypto : 321992\n",
      "Crypto : 5038\n",
      "Crypto : 310829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cysacenda/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-caaf97b84f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                       'RandomForestClassifier':get_RandomForestClassifier()}.items():\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mclf_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_to_be_considered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtresholds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0;31m# logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    975\u001b[0m         \"\"\"\n\u001b[1;32m    976\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 977\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 376\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0miprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 175\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0minplace_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDERIVATIVES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0minplace_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             coef_grads, intercept_grads = self._compute_loss_grad(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py\u001b[0m in \u001b[0;36minplace_relu_derivative\u001b[0;34m(Z, delta)\u001b[0m\n\u001b[1;32m    167\u001b[0m          \u001b[0mThe\u001b[0m \u001b[0mbackpropagated\u001b[0m \u001b[0merror\u001b[0m \u001b[0msignal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmodified\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_XGBClassifier():\n",
    "    return XGBClassifier()\n",
    "\n",
    "def get_MLPClassifier():\n",
    "    return MLPClassifier(hidden_layer_sizes = [130, 130], solver='lbfgs',\n",
    "                     random_state = 0)\n",
    "\n",
    "def get_RandomForestClassifier():\n",
    "    return RandomForestClassifier(random_state=0, class_weight=\"balanced\", max_depth=5)\n",
    "\n",
    "\n",
    "# loop on different dataset size with different number of cryptos for learning (cf. params)\n",
    "for nb_cryptos in param_datasets_nb_cryptos:\n",
    "    # get n first cryptos ids\n",
    "    ids_cryptos = param_crypto_learning[:nb_cryptos]\n",
    "    dict_df = alg_preproc.get_global_datasets_for_cryptos(ids_cryptos)\n",
    "    \n",
    "    # loop on different y (prediction in future +3h, +6h, +1d, ect.)\n",
    "    for term, arr_pct_change in params_y.items():\n",
    "        df_logging = pd.DataFrame()\n",
    "        y_to_be_considered = 'y_+XXX_classif'.replace('XXX', term)\n",
    "        # loop on different price change in percentage for target\n",
    "        for close_price_targeted in arr_pct_change:            \n",
    "            # do +/- (increase or decrease close price %)\n",
    "            for factor in [-1, +1]:\n",
    "                X_train, X_test, y_train, y_test = alg_preproc.get_preprocessed_data(dict_df, dict_hours_labels, \n",
    "                                                                                 close_price_targeted * factor, \n",
    "                                                                                 predict_only_one_crypto,\n",
    "                                                                                 do_scale=do_scale, \n",
    "                                                                                 do_pca=do_pca)\n",
    "                \n",
    "                # Take into account param_crypto_predicting => Faire 1 seule à la fois chacune son tour puis tout ?\n",
    "                \n",
    "                # For each algo, find good base params \n",
    "                for clf_name, clf in {'XGBClassifier':get_XGBClassifier(), 'MLPClassifier':get_MLPClassifier(), \n",
    "                                      'RandomForestClassifier':get_RandomForestClassifier()}.items():\n",
    "                    \n",
    "                    clf_trained = clf.fit(X_train, y_train[y_to_be_considered])\n",
    "                    for threshold in tresholds:\n",
    "                        # logging\n",
    "                        p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12 = evaluate_model_formated(clf, X_train, y_train[y_to_be_considered].values, threshold, type(clf) != MLPClassifier)\n",
    "                        log_values = pd.Series([datetime.now(), 'Success', '', len(ids_cryptos), term, close_price_targeted * factor, clf_name, do_scale, do_pca, p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12])\n",
    "                        df_logging = df_logging.append(log_values, ignore_index=True)\n",
    "                        \n",
    "                        # TODO : Ajouter Xtrain et XTest !\n",
    "                    \n",
    "#                     try:\n",
    "#                         clf_trained = clf.fit(X_train, y_train[y_to_be_considered])\n",
    "                        \n",
    "#                         for treshold in tresholds:\n",
    "#                             # logging\n",
    "#                             log_values = pd.Series([datetime.now(), 'Success', '', len(ids_cryptos), term, close_price_targeted * factor, clf_name, do_scale, do_pca, evaluate_model_formated(clf, X_train, y_train[y_to_be_considered].values, threshold=threshold)])\n",
    "#                             df_logging = df_logging.append(log_values, ignore_index=True)\n",
    "                        \n",
    "#                     except Exception as e:\n",
    "#                         # logging\n",
    "#                         log_values = pd.Series([datetime.now(), 'Error', str(e), len(ids_cryptos), term, close_price_targeted * factor, clf_name, do_scale, do_pca,\n",
    "#                                                None, None,None, None,None, None,None, None,None, None,None, None,])\n",
    "#                         df_logging = df_logging.append(log_values, ignore_index=True)\n",
    "                    clf_trained = clf.fit(X_train, y_train[y_to_be_considered])\n",
    "                \n",
    "        # insert data into database\n",
    "        df_logging.columns = ['timestamp', 'status', 'error_message', 'param_crypto_learning', 'param_term', 'param_close_price_targeted', \n",
    "                              'param_Algo', 'param_do_scale', 'param_do_pca', 'confusion_TN', 'confusion_FP', 'confusion_FN',\n",
    "                              'confusion_TP', 'precision_score', 'recall_score', 'f1_score', 'support_True', 'support_False',\n",
    "                              'feat_importance_1', 'feat_importance_2', 'feat_importance_3']\n",
    "        df_logging.to_sql(name='logging_trt', con=connection, if_exists = 'append', index=False)\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ PARAMETERS ------------------ #\n",
    "# ['y_+3h_value', 'y_+3h_classif',, 'y_+6h_value', 'y_+6h_classif', 'y_+12h_value', 'y_+12h_classif','y_+1d_value', 'y_+1d_classif', 'y_+2d_value', 'y_+2d_classif', 'y_+3d_value', 'y_+3d_classif', 'y_+7d_value', 'y_+7d_classif', 'y_+15d_value', 'y_+15d_classif', 'y_+30d_value', 'y_+30d_classif']\n",
    "id_cryptocompare = \"7605\" # ether 7605\n",
    "predict_only_one_crypto = False\n",
    "y_to_be_considered = 'y_+1d_classif' #1d_classif\n",
    "close_price_increase_targeted = +5\n",
    "threshold = 0.5\n",
    "dict_hours_labels  = {3:'3h', 6:'6h', 12:'12h', 24:'1d', 24*2:'2d', 24*3:'3d', 24*7:'7d', 24*15:'15d', 24*30:'30d'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ LOAD DATA FROM DATABASE ------------------ #\n",
    "\n",
    "# ONE CRYPTO\n",
    "#df = alg_preproc.get_global_dataset_for_crypto(\"236131\")\n",
    "#df2 = df.reset_index(drop=True)\n",
    "\n",
    "# TOP N CRYPTOS\n",
    "#dict_df = alg_preproc.get_global_datasets_for_top_n_cryptos(2)\n",
    "\n",
    "# ------------------ LOAD DATA FROM FILE ------------------ #\n",
    "#save_obj(dict_df, 'dict_df_2018_10_26')\n",
    "#dict_df = load_obj('dict_df_2018_10_26') # top 30-40 \n",
    "#dict_df = load_obj('dict_df_2018_10_31') # top 10 \n",
    "#dict_df = load_obj('dict_df_2018_11_07') # top 10 \n",
    "#dict_df = load_obj('dict_df_2018_10_31_top2') # top 2\n",
    "\n",
    "dict_df = load_obj('dict_df_2018_11_13') # top 30\n",
    "#dict_df.keys()\n",
    "X_train, X_test, y_train, y_test = alg_preproc.get_preprocessed_data(dict_df, dict_hours_labels, \n",
    "                                                                     close_price_increase_targeted, \n",
    "                                                                     predict_only_one_crypto,\n",
    "                                                                     do_scale=True, \n",
    "                                                                     do_pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion)\n",
    "confusion[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : RANDOM FOREST WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "rf_best_estimator, rf_best_params = alg_gridsearch.start_randomizedSearchCV_random_forest(X_train_scaled, \n",
    "                                                                                          y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', rf_best_estimator, X_train_scaled, y_train[y_to_be_considered], X_train_scaled.columns, do_precision_recall_curve=True, do_features_importance=True, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', rf_best_estimator, X_test_scaled, y_test[y_to_be_considered], X_test_scaled.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : MLPC WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "mlpc_best_estimator, mlpc_best_params = alg_gridsearch.start_randomizedSearchCV_mlpc(X_train_scaled, \n",
    "                                                                                     y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', mlpc_best_estimator, X_train_scaled, y_train[y_to_be_considered], X_train_scaled.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', mlpc_best_estimator, X_test_scaled, y_test[y_to_be_considered], X_test_scaled.columns, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : XGBoost WITH RANDOMGRIDSEARCH\n",
    "# -----------------------\n",
    "\n",
    "xgboost_best_estimator, xgboost_best_params = alg_gridsearch.start_randomizedSearchCV_xgboost(X_train, \n",
    "                                                                                           y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('GradientBoostingClassifier - Train', xgboost_best_estimator, X_train, y_train[y_to_be_considered], None, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('GradientBoostingClassifier - Test', xgboost_best_estimator, X_test, y_test[y_to_be_considered], None, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : RANDOM FOREST\n",
    "# -----------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#, n_estimators=100, max_features='auto', max_depth=5, criterion='entropy', class_weight=\"balanced\"\n",
    "clf = RandomForestClassifier(random_state=0, class_weight=\"balanced\", max_depth=5).fit(X_train, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('RandomForestClassifier - Train', clf, X_train, y_train[y_to_be_considered], None, do_precision_recall_curve=True, do_features_importance=True, threshold=threshold)\n",
    "show_model_accuracy('RandomForestClassifier - Test', clf, X_test, y_test[y_to_be_considered], None, do_precision_recall_curve=True, do_features_importance=False, threshold=threshold)\n",
    "\n",
    "# proba : to be shown by prediction, bien comprendre !\n",
    "probas = clf.predict_proba(X_test)[:,1]\n",
    "pprint(np.sort(probas))\n",
    "pprint(clf.get_params())\n",
    "\n",
    "# clf.decision_path(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : MLPClassifier - Neural Network (cf. Module+4 for tuning)\n",
    "# -----------------------\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [130, 130], solver='lbfgs',\n",
    "                     random_state = 0).fit(X_train, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('MLPClassifier - Neural Network - Train', nnclf, X_train, y_train[y_to_be_considered], None, do_roc_curve=True, do_precision_recall_curve=True, do_precision_recall_vs_treshold=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('MLPClassifier - Neural Network - Test', nnclf, X_test, y_test[y_to_be_considered], None, do_roc_curve=True, do_precision_recall_curve=True, do_precision_recall_vs_treshold=True, do_features_importance=False, threshold=threshold)\n",
    "\n",
    "# proba : to be shown by prediction, bien comprendre !\n",
    "#print(pd.DataFrame(nnclf.predict_proba(X_test_scaled)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# ALGO : XGBOOST (cf. Module+4 for tuning)\n",
    "# -----------------------\n",
    "from xgboost import XGBClassifier\n",
    "# Generally, the Scale_pos_weight is the ratio of number of negative class to the positive class. \n",
    "# Suppose, the dataset has 90 observations of negative class and 10 observations of positive class, \n",
    "# then ideal value of scale_pos_Weight should be 9. You can check the following link. \n",
    "# http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "\n",
    "xgbc = XGBClassifier().fit(X_train, y_train[y_to_be_considered])\n",
    "\n",
    "show_model_accuracy('XGBClassifier - Train', xgbc, X_train, y_train[y_to_be_considered], pX_columns=None, do_roc_curve=True, do_precision_recall_curve=True, do_precision_recall_vs_treshold=True, do_features_importance=False, threshold=threshold)\n",
    "show_model_accuracy('XGBClassifier - Test', xgbc, X_test, y_test[y_to_be_considered], pX_columns=None, do_roc_curve=True, do_precision_recall_curve=True, do_precision_recall_vs_treshold=True, do_features_importance=True, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
